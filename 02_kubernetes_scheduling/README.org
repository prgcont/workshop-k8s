* Kubernetes Scheduling
  :PROPERTIES:
  :CUSTOM_ID: kubernetes-scheduling
  :END:

The purpose of this workshop is to help you expand your Kubernetes
knowledge. In this part we will look how to run more sophisticated
deployments and will show you how you can use python to easily interact
with Kubernetes API server. We will be using Gordon application form
previous workshop, so be sure you have it available.

** Topics                                                         :TOC_2_gh:
  :PROPERTIES:
  :CUSTOM_ID: topics
  :END:

- [[#kubernetes-scheduling][Kubernetes Scheduling]]
  - [[#setup][Setup]]
  - [[#statefulsets][StatefulSets]]
  - [[#kubernetes-api][Kubernetes API]]
  - [[#daemonsets][DaemonSets]]

** Setup
   :PROPERTIES:
   :CUSTOM_ID: setup
   :END:

export kubernetes username via:

If using minikube, export use:

#+BEGIN_SRC sh
$ export KUBERNETES_USER=default
#+END_SRC

If using kubernetes cluster provided by instructor, use

#+BEGIN_SRC sh
$ export KUBERNETES_USER=<YOUR_CUSTOM_USERNAME>
#+END_SRC

** StatefulSets
   :PROPERTIES:
   :CUSTOM_ID: statefulsets
   :END:

StatefulSets are the way of how to run your stateful application inside of Kubernetes.
In comparison with ReplicaSet it offers you:

1) Stable network identity for your pods
2) Controlled order of scaling and termination
3) Controlled update environment (updating in predictable order)

We will start by creating our first stateful service.
Change =${REGISTRY_USER}= to point to your image or use =prgcont= if you want to use our image.
Define following object to Kubernetes (use =kubectl create -f= command for it).

#+BEGIN_SRC yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: gordon
      labels:
        app: gordon
    spec:
      ports:
      - port: 80
        name: web
      clusterIP: None
      selector:
        app: gordon
    ---
    apiVersion: apps/v1
    kind: StatefulSet
    metadata:
      name: webgordon
    spec:
      serviceName: "gordon"
      replicas: 2
      selector:
        matchLabels:
          app: gordon
      template:
        metadata:
          labels:
            app: gordon
        spec:
          containers:
          - name: gordon
            image: ${REGISTRY_USER}/gordon:v1.0
            ports:
            - containerPort: 8080
              name: web
            volumeMounts:
            - name: www
              mountPath: /mnt/vol
      volumeClaimTemplates:
      - metadata:
          name: www
        spec:
          accessModes: [ "ReadWriteOnce" ]
          resources:
            requests:
              storage: 1Gi
#+END_SRC

Then you can see what happened by executing:

#+BEGIN_SRC sh
    $ kubectl get all
#+END_SRC

You should see the service and two pods =webgordon-0= and =webgordon-1=

*** How Can I Access My App Inside Cluster?
    :PROPERTIES:
    :CUSTOM_ID: how-can-i-access-my-app-inside-cluster
    :END:

To access your app we will hook inside Kubernetes network via =kubectl proxy= command, so please open a new terminal and run

#+BEGIN_SRC sh
    $  kubectl proxy
#+END_SRC

! IMPORTANT - Do not stop proxy as following commands will not work.

Now you can try to access your application via service.

#+BEGIN_SRC sh
$ curl http://localhost:8001/api/v1/namespaces/${KUBERNETES_USER}/services/gordon/proxy/
#+END_SRC

*and this will fail*. We can now try to access our pods via:

#+BEGIN_SRC sh
$ curl http://localhost:8001/api/v1/namespaces/${KUBERNETES_USER}/pods/webgordon-1/proxy/
#+END_SRC

So how can I access my app? If you are running stateful application you probably don't want to have any automatic load balancing and you can use predictable DNS record for any pod.
We can try it by executing shell inside of our container and curling another one:

#+BEGIN_SRC sh
$ kubectl exec -ti  webgordon-1 bash
$ curl webgordon-0.gordon:8080
#+END_SRC

As you can see you can access your pods by =webgordon-$id.gorgon= nameinside of your cluster.

If you examine the service object you will find out, that we've created a [[https://kubernetes.io/docs/concepts/services-networking/service/#headless-services][headless service]].

*** Tasks
    :PROPERTIES:
    :CUSTOM_ID: tasks
    :END:

- Scale your application to 4 pods
- Examine all resources, (pods, pvc, services) that were created.
- Find a =template= in resource definition to see how it works
- Try to access all of the stateful pods in the cluster
- Scale your application back to 2 pods
- Examine all resources again

*** Advanced tasks
    :PROPERTIES:
    :CUSTOM_ID: advanced-tasks
    :END:

- Suggest a way of how to access your stateful application via ingress controller
- Implement previous tasks

** Kubernetes API
   :PROPERTIES:
   :CUSTOM_ID: kubernetes-api
   :END:

In this chapter we will start to talk with Kubernetes API. We will do it by writing a very simple pod scheduler.
Language of our choice is Python, but you can use almost any other language - the principles will the same.

*** Preparing Python Env
    :PROPERTIES:
    :CUSTOM_ID: preparing-python-env
    :END:

We will start by creating Python virtual environment

#+BEGIN_SRC sh
    $ virtualenv ~/kube
    $ source ~/kube/bin/activate
    $ pip install kubernetes
#+END_SRC

*** Preparing pod
    :PROPERTIES:
    :CUSTOM_ID: preparing-pod
    :END:

We will now create a pod which will tell Kubernetes to wait for our custom scheduler.
You can do it by feeding Kubernetes with following YAML:

#+BEGIN_SRC sh
    kubectl apply -f - <<EOF
    apiVersion: v1
    kind: Pod
    metadata:
      name: hello
    spec:
      schedulerName: PrgContSched
      containers:
      - name: hello
        image: ${REGISTRY_USER}/gordon:v1.0
    EOF
#+END_SRC

Now if we will run =kubectl get pods= we'll see our pod stuck in a =Pending= state.
This is the initial state of a pod and Kubernetes default scheduler is ignoring this pod as we marked our pod to be schedulable via =PrgContSched= scheduler.

*** Talking to Kubernetes API
    :PROPERTIES:
    :CUSTOM_ID: talking-to-kubernetes-api
    :END:

First we will create a simple Python script which will connect to Kubernetes and will list all Pods waiting to be scheduled:

#+BEGIN_SRC python
    from kubernetes import client, config, watch

    # Following line is sourcing your ~/.kube/config so you are authenticated same way
    # as kubectl is
    config.load_kube_config()
    v1 = client.CoreV1Api()
    namespace = config.list_kube_config_contexts()[1]["context"]["namespace"]

    def main():
        w = watch.Watch()
        for event in w.stream(v1.list_namespaced_pod, namespace):
            print("pod: '%s', phase: '%s'." % (event['object'].metadata.name,
                                               event['object'].status.phase))
                       
    if __name__ == '__main__':
        main()
#+END_SRC

You should see your pod in the =Pending= state.

*** Tasks
    :PROPERTIES:
    :CUSTOM_ID: tasks-1
    :END:

- Look at [[https://github.com/kubernetes-client/python/blob/master/kubernetes/docs/V1Pod.md][Kubernetes Python API docs]] and adjust python script to print name of the requested scheduler too.

*** Scheduling a Pod
    :PROPERTIES:
    :CUSTOM_ID: scheduling-a-pod
    :END:

To be able to schedule our pod we will create a simple Schedule function:

#+BEGIN_SRC python
    def scheduler(name, node, namespace=namespace):
            
        target=client.V1ObjectReference()
        target.kind = "Node"
        target.apiVersion = "v1"
        target.name = node
        
        meta = client.V1ObjectMeta()
        meta.name = name
        
        body = client.V1Binding(metadata=meta, target=target)
        
        return v1.create_namespaced_binding(namespace, body)
#+END_SRC

and adjust our main function to look like:

#+BEGIN_SRC python
    def main():
        w = watch.Watch()
        for event in w.stream(v1.list_namespaced_pod, namespace):
            print("pod: '%s', phase: '%s' %s." % (event['object'].metadata.name,
                                               event['object'].status.phase,
                                               event['object'].spec.scheduler_name))
            if event['object'].status.phase == "Pending" and event['object'].spec.scheduler_name == "PrgContSched":
                try:
                    res = scheduler(event['object'].metadata.name, 'minikube')
                except Exception as ex:
                    print(ex)
#+END_SRC

When you run your function it should schedule a pod. If you get an exception you can probably ignore it as there is currently bug in this [[https://github.com/kubernetes-client/gen/issues/52][API]].

Check pod state by invoking:

#+BEGIN_SRC sh
$ kubectl get pods
#+END_SRC

*** Moving Your Scheduler Inside of Your Cluster
    :PROPERTIES:
    :CUSTOM_ID: moving-your-scheduler-inside-of-your-cluster
    :END:

To move your scheduler to be run inside your Kubernetes cluster you need to change only one line =config.load_kube_config()= to =config.load_incluster_config()= so your scheduler will look like:

#+BEGIN_SRC python
    from kubernetes import client, config, watch

    # Following line is sourcing your ~/.kube/config so you are authenticated same way
    # as kubectl is
    config.load_kube_config()
    namespace = config.list_kube_config_contexts()[1]["context"]["namespace"]
    print("Namespace from kubeconfig: {}".format(namespace))

    v1 = client.CoreV1Api()


    def scheduler(name, node):

        target=client.V1ObjectReference()
        target.kind = "Node"
        target.apiVersion = "v1"
        target.name = node

        meta = client.V1ObjectMeta()
        meta.name = name

        body = client.V1Binding(metadata=meta, target=target)

        return v1.create_namespaced_binding(namespace, body)

    def main():
        w = watch.Watch()
        for event in w.stream(v1.list_namespaced_pod, namespace):
            print("pod: '%s', phase: '%s' %s." % (event['object'].metadata.name,
                                               event['object'].status.phase,
                                               event['object'].spec.scheduler_name))
            if event['object'].status.phase == "Pending" and event['object'].spec.scheduler_name == "PrgContSched":
                try:
                    res = scheduler(event['object'].metadata.name, 'worker-01')
                except Exception as ex:
                    print(ex)


    if __name__ == '__main__':
        main()
#+END_SRC

*** Tasks
    :PROPERTIES:
    :CUSTOM_ID: tasks-2
    :END:

- Build this scheduler as a Docker image
- Deploy it to the Kubernetes
- Schedule a pod with it

** DaemonSets
   :PROPERTIES:
   :CUSTOM_ID: daemonsets
   :END:

[[https://kubernetes.io/docs/concepts/workloads/controllers/daemonset][DaemonSets]]
are a special objects in Kubernetes clusters which enables you to run 1 instance of your application on every node of your Cluster.

This is very useful for deploying infrastructure like types of applications (for example. Prometheus or CEPH/Gluster clusters).

To create a DaemonSet please feed following object to a Kubernetes cluster. Don't forget to change =${REGISTRY_USER}= variable!


#+BEGIN_SRC yaml
    apiVersion: apps/v1
    kind: DaemonSet
    metadata:
      name: gordon
    spec:
      selector:
        matchLabels:
          name: gordon
      template:
        metadata:
          labels:
            name: gordon
        spec:
          tolerations:
          - key: node-role.kubernetes.io/master
            effect: NoSchedule
          containers:
          - name: gordon
            image: ${REGISTRY_USER}/gordon:v1.0
          terminationGracePeriodSeconds: 30
#+END_SRC

*** Tasks
    :PROPERTIES:
    :CUSTOM_ID: tasks-3
    :END:

- Look at possible [[https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/#alternatives-to-daemonset][alternatives]] to DaemonSets.
- Suggest how to communicate with DaemonSets pods as load balancing is probably not good idea here. Explain why.
